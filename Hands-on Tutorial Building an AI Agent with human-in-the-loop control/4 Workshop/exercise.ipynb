{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Workshop Building an AI Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "### Install all necessary dependencies. Select Python 3.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "### Load dependencies from helper file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load environment variables from .env\n",
    "%run -i helper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "### Initialize Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have real-time capabilities to provide the current date. You can check the date on your device or calendar.\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = init_llm('gpt-4o', max_tokens=2048, temperature=0)\n",
    "# llm = init_llm('gemini-2.5-pro', max_tokens=4192, temperature=0, init_func=google_vertexai_init_chat_model)\n",
    "\n",
    "llm.invoke(\"What day is it?\").content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Exercise\n",
    "**Exercise:** Give the Agent a function `get_today()` and invoke it asking about the date.\n",
    "\n",
    "<details>\n",
    "<summary>Show solution</summary>\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def get_today() -> str:\n",
    "    \"This tool retrieves the current date and time.\"\n",
    "    return date.today()\n",
    "\n",
    "tools = [get_today]\n",
    "tool_llm = llm.bind_tools(tools)\n",
    "answer = tool_llm.invoke(\"What's todays date?\")\n",
    "\n",
    "display(f\"AI Response: {answer.content}\" if answer.content else \"No AI Message.\")\n",
    "display(f\"AI Actions: {answer.additional_kwargs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No AI Message.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AI Actions: {\\'tool_calls\\': [{\\'id\\': \\'call_2bQpYDttu7ymj4ijIpYpJQCh\\', \\'function\\': {\\'arguments\\': \\'{\"location\": \"New York\"}\\', \\'name\\': \\'get_current_weather\\'}, \\'type\\': \\'function\\'}, {\\'id\\': \\'call_5hEEWCvZhtLolZq6CVsAcIey\\', \\'function\\': {\\'arguments\\': \\'{\"location\": \"Los Angeles\"}\\', \\'name\\': \\'get_current_weather\\'}, \\'type\\': \\'function\\'}], \\'refusal\\': None}'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Implement the function\n",
    "def get_today():\n",
    "    \"\"\"TODO: Define this docstring.\"\"\"\n",
    "    pass\n",
    "\n",
    "#Add the tool\n",
    "tools = []\n",
    "\n",
    "agent_llm = llm.bind_tools(tools)\n",
    "\n",
    "#Add message for the agent\n",
    "answer = agent_llm.invoke(\"\")\n",
    "\n",
    "display(f\"AI Response: {answer.content}\" if answer.content else \"No AI Message.\")\n",
    "display(f\"AI Actions: {answer.additional_kwargs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No AI Message.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"AI Actions: {'tool_calls': [{'id': 'call_7Q1urEZEoNR4GwNEpWsY0sRu', 'function': {'arguments': '{}', 'name': 'get_today'}, 'type': 'function'}], 'refusal': None}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@tool\n",
    "def get_today() -> str:\n",
    "    \"This tool retrieves the current date and time.\"\n",
    "    return date.today()\n",
    "\n",
    "tools = [get_today]\n",
    "tool_llm = llm.bind_tools(tools)\n",
    "answer = tool_llm.invoke(\"What's todays date?\")\n",
    "\n",
    "display(f\"AI Response: {answer.content}\" if answer.content else \"No AI Message.\")\n",
    "display(f\"AI Actions: {answer.additional_kwargs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Build a ReAct agent (LLM with tools to ReAct Agent)\n",
    "Now we implement tool execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date is September 26, 2025.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "tools = [get_today]\n",
    "react_agent = create_react_agent(model=llm, tools=tools)\n",
    "answer = react_agent.invoke({\"messages\": [\"What's todays date?\"]})[\"messages\"]\n",
    "print(answer[-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Stream the agents output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <iframe\n",
       "    sandbox=\"allow-scripts\"\n",
       "    src=\"data:text/html;base64,PCFkb2N0eXBlIGh0bWw+CiAgICA8aHRtbD48aGVhZD48bWV0YSBjaGFyc2V0PSJ1dGYtOCI+PC9oZWFkPgogICAgPGJvZHk+CiAgICA8ZGl2IGNsYXNzPSJtZXJtYWlkIj4tLS0KY29uZmlnOgogIGZsb3djaGFydDoKICAgIGN1cnZlOiBsaW5lYXIKLS0tCmdyYXBoIFREOwoJX19zdGFydF9fKFs8cD5fX3N0YXJ0X188L3A+XSk6OjpmaXJzdAoJYWdlbnQoYWdlbnQpCgl0b29scyh0b29scykKCV9fZW5kX18oWzxwPl9fZW5kX188L3A+XSk6OjpsYXN0CglfX3N0YXJ0X18gLS0+IGFnZW50OwoJdG9vbHMgLS0+IGFnZW50OwoJYWdlbnQgLS4tPiB0b29sczsKCWFnZW50IC0uLT4gX19lbmRfXzsKCWNsYXNzRGVmIGRlZmF1bHQgZmlsbDojZjJmMGZmLGxpbmUtaGVpZ2h0OjEuMgoJY2xhc3NEZWYgZmlyc3QgZmlsbC1vcGFjaXR5OjAKCWNsYXNzRGVmIGxhc3QgZmlsbDojYmZiNmZjCjwvZGl2PgogICAgPHNjcmlwdCBzcmM9Imh0dHBzOi8vY2RuLmpzZGVsaXZyLm5ldC9ucG0vbWVybWFpZC9kaXN0L21lcm1haWQubWluLmpzIj48L3NjcmlwdD4KICAgIDxzY3JpcHQ+bWVybWFpZC5pbml0aWFsaXplKHsgc3RhcnRPbkxvYWQ6IHRydWUgfSk7PC9zY3JpcHQ+CiAgICA8L2JvZHk+PC9odG1sPgogICAg\"\n",
       "    style=\"width:100%;height:480px;border:0;\">\n",
       "    </iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's todays date?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_today (call_lQN1b1IIzJnPK6DT0DH9238S)\n",
      " Call ID: call_lQN1b1IIzJnPK6DT0DH9238S\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_today\n",
      "\n",
      "2025-09-26\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Today's date is September 26, 2025.\n"
     ]
    }
   ],
   "source": [
    "display_graph(react_agent)\n",
    "for msg in answer:\n",
    "    msg.pretty_print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Giving tools to our LangGraph Agent\n",
    "...\n",
    "**The Critical Role of Docstrings**\n",
    "\n",
    "For a LangGraph agent to effectively use a custom function as a \"tool,\" it must first understand what the function does. The primary source of this understanding for the agent is the function's docstring. The LLM parses the docstring to learn the tool's purpose, its required parameters, and what kind of output to expect. A well-written docstring is therefore essential for the agent to know when and how to use the tool correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Exercise\n",
    "**Documenting an Agent Tool**\n",
    "\n",
    "In the next cell, you will find a `get_records()` function designed to fetch data from an API. Your task is to understand the function and complete its docstring. \n",
    "\n",
    "(This exercise highlights how crucial clear documentation is, as it directly enables the agent to correctly utilize the function to fulfill user requests.)\n",
    "\n",
    "<details>\n",
    "<summary>Show solution </summary>\n",
    "\n",
    "```python\n",
    "\n",
    "odata_endpoint = os.getenv(\"ODATA_ENDPOINT\")\n",
    "if not odata_endpoint:\n",
    "    raise ValueError(\"ODATA_ENDPOINT environment variable is not set.\")\n",
    "\n",
    "@tool\n",
    "def get_records(top:int) -> str:\n",
    "    \"\"\"Fetch ExternalTimeData records for the current user.\n",
    "    Args:\n",
    "        top: Maximum number of records to return.\n",
    "    Returns:\n",
    "        JSON response with time records or error message.\n",
    "    \"\"\"\n",
    "    # Built query\n",
    "    params = {}\n",
    "    \n",
    "    # Limit number of records returned\n",
    "    if top is not None:\n",
    "        params['$top'] = top\n",
    "\n",
    "    # Filter by current userID\n",
    "    params['$filter'] = f'userId eq {user_id}'\n",
    "    query_text = urllib.parse.urlencode(params, safe='(),')\n",
    "\n",
    "    # Make GET request to the SuccessFactors OData API\n",
    "    table = 'ExternalTimeData'\n",
    "    url = f'{odata_endpoint}{table}?{query_text}'\n",
    "    response = requests.get(url, headers=get_header)\n",
    "\n",
    "    # Process response\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        return f'Error: {response.content}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_records(top:int) -> str:\n",
    "    \"\"\"TODO Understand the function and fill in the docstring.\n",
    "    \"\"\"\n",
    "    # Built query\n",
    "    params = {}\n",
    "    \n",
    "    # Limit number of records returned\n",
    "    if top is not None:\n",
    "        params['$top'] = top\n",
    "\n",
    "    # Filter by current userID\n",
    "    params['$filter'] = f'userId eq {user_id}'\n",
    "    query_text = urllib.parse.urlencode(params, safe='(),')\n",
    "\n",
    "    # Make GET request to the SuccessFactors OData API\n",
    "    table = 'ExternalTimeData'\n",
    "    url = f'{odata_endpoint}{table}?{query_text}'\n",
    "    response = requests.get(url, headers=get_header)\n",
    "\n",
    "    # Process response\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        return f'Error: {response.content}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#SuccessFactors OData API endpoint to fetch time records for the current user.\n",
    "odata_endpoint = os.getenv(\"ODATA_ENDPOINT\")\n",
    "if not odata_endpoint:\n",
    "    raise ValueError(\"ODATA_ENDPOINT environment variable is not set.\")\n",
    "    \n",
    "@tool\n",
    "def get_records(top:int) -> str:\n",
    "    \"\"\"Fetch ExternalTimeData records for the current user.\n",
    "    Args:\n",
    "        top: Maximum number of records to return.\n",
    "    Returns:\n",
    "        JSON response with time records or error message.\n",
    "    \"\"\"\n",
    "    # Built query\n",
    "    params = {}\n",
    "    \n",
    "    # Limit number of records returned\n",
    "    if top is not None:\n",
    "        params['$top'] = top\n",
    "\n",
    "    # Filter by current userID\n",
    "    params['$filter'] = f'userId eq {user_id}'\n",
    "    query_text = urllib.parse.urlencode(params, safe='(),')\n",
    "\n",
    "    # Make GET request to the SuccessFactors OData API\n",
    "    table = 'ExternalTimeData'\n",
    "    url = f'{odata_endpoint}{table}?{query_text}'\n",
    "    response = requests.get(url, headers=get_header)\n",
    "\n",
    "    # Process response\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        return f'Error: {response.content}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Built a first version of our agent\n",
    "Update the agent's tools and ask for the latest records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no time records available.\n"
     ]
    }
   ],
   "source": [
    "tools = [get_today, get_records]\n",
    "\n",
    "react_agent = create_react_agent(model=llm, tools=tools)\n",
    "answer = react_agent.invoke({\"messages\": [\"Get me the latest time records.\"]})[\"messages\"]\n",
    "print(answer[-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "No records so far. Let's add some."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Add a tool for adding records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LangGraph requires typing information for structured data inputs/outputs. Define a BaseModel for the input data.\n",
    "class ExternalTimeData(BaseModel):\n",
    "    \"\"\"Represents a single time record.\"\"\"\n",
    "    startDate: str = Field(description=\"The date of the work period. Example: 2023-09-15\")\n",
    "    startTime: str = Field(description=\"The start time of the work period in ISO 8601 format. Example: PT09H00M00S\")\n",
    "    endTime: str = Field(description=\"The end time of the work period in ISO 8601 format. Example: PT17H00M00S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def post_records(data: ExternalTimeData, confirmation_message : str):\n",
    "    \"\"\"Post a single work time record to the API. The user is asked for confirmation first.\n",
    "\n",
    "    Args:\n",
    "        data (ExternalTimeData): An object with the details for the time record. It must contain:\n",
    "            - startDate (str): The work date in 'YYYY-MM-DD' format.\n",
    "            - startTime (str): The work start time in ISO 8601 duration format (e.g., 'PT09H00M00S').\n",
    "            - endTime (str): The work end time in ISO 8601 duration format (e.g., 'PT17H30M00S').\n",
    "        confirmation_message (str): A detailed summary for the user to confirm, including the specific date and time range.\n",
    "            Example: 'Confirm work time from 09:00 to 17:30 on Friday, September 26th 2025.'\n",
    "    \"\"\"\n",
    "    # Build POST payload\n",
    "    payload, url = build_post_payload(data, odata_endpoint)\n",
    "    # Make POST request to the SuccessFactors OData API endpoint\n",
    "    response = requests.post(url, headers=post_header, json=payload)\n",
    "\n",
    "    # Process response\n",
    "    if response.status_code in (200, 201):\n",
    "        return f'Entity created successfully: {data}'\n",
    "    else:\n",
    "        return  f'Error creating entity ({data}):  {response.status_code}: {response.content}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Exercise\n",
    "**Preparing Tool Inputs**\n",
    "\n",
    "An agent needs to know not just *what* a tool does, but also *how* to provide the correct inputs. The `post_records` function requires data in a specific format to log time entries.\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "In the next cell, you'll find an `example_record`. Examine the `post_records` function and its docstring to understand the required data structure. Then, fill in the `example_record` with valid data. This exercise simulates how the agent prepares data before calling a tool.\n",
    "\n",
    "<details>\n",
    "<summary>Show solution</summary>\n",
    "\n",
    "```python\n",
    "# Create example record like the agent would\n",
    "example_record: ExternalTimeData = {\n",
    "    \"startDate\": \"2025-01-01\",\n",
    "    \"startTime\": \"PT09H00M00S\",\n",
    "    \"endTime\": \"PT18H30M00S\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO Create example record like the agent would\n",
    "example_record = ExternalTimeData(\n",
    "    startDate=\"\",\n",
    "    startTime=\"\",\n",
    "    endTime=\"\"\n",
    ")\n",
    "# Uncomment to try out\n",
    "#post_records.invoke({\"data\": example_record, \"confirmation_message\": \"No confirmation implemented yet.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Entity created successfully: startDate='2025-01-01' startTime='PT09H00M00S' endTime='PT18H30M00S'\""
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create example record like the agent would\n",
    "example_record = ExternalTimeData(\n",
    "    startDate=\"2025-01-01\",\n",
    "    startTime=\"PT09H00M00S\",\n",
    "    endTime=\"PT18H30M00S\"\n",
    ")\n",
    "\n",
    "post_records.invoke({\"data\": example_record, \"confirmation_message\": \"No confirmation implemented yet.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Create a ReAct Agent with all three tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_today (call_o76EHAO6U5NWxZIJ6hUWbdQ4)\n",
      " Call ID: call_o76EHAO6U5NWxZIJ6hUWbdQ4\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_today\n",
      "\n",
      "2025-09-26\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  post_records (call_cmN6Es1N0yr4ylcgd94HmGdA)\n",
      " Call ID: call_cmN6Es1N0yr4ylcgd94HmGdA\n",
      "  Args:\n",
      "    data: {'startDate': '2025-09-26', 'startTime': 'PT09H00M00S', 'endTime': 'PT18H30M00S'}\n",
      "    confirmation_message: Confirm work time from 09:00 to 18:30 on Friday, September 26th 2025.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: post_records\n",
      "\n",
      "Entity created successfully: startDate='2025-09-26' startTime='PT09H00M00S' endTime='PT18H30M00S'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your work time from 09:00 to 18:30 on Friday, September 26th, 2025 has been successfully logged into the system.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a react agent with all three tools\n",
    "tools = [get_today, get_records, post_records]\n",
    "react_agent = create_react_agent(model=llm, tools=tools)\n",
    "\n",
    "# Stream the agent's actions and final response\n",
    "# TODO Modify the user input if you want to test different scenarios\n",
    "stream = react_agent.stream({\"messages\": [\"Today I worked from 09:00 to 18:30. Please log this time entry into the system.\"]})\n",
    "process_output(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Importance of Human-in-the-loop control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Missing Human-In-The-Loop (HITL) control with the current tooling could lead to:\n",
       "\n",
       "1. **Incorrect Time Records**: Tools like `functions.post_records` could post inaccurate work time records without human verification, leading to errors in time tracking.\n",
       "2. **Data Overload**: Using `functions.get_records` without HITL might retrieve excessive or irrelevant data, making it difficult to manage and analyze.\n",
       "3. **Automation Errors**: `multi_tool_use.parallel` could execute multiple tools simultaneously without human oversight, potentially causing conflicts or errors in data processing.\n",
       "\n",
       "Overall, the absence of HITL control could result in data inaccuracies, inefficiencies, and potential conflicts in automated processes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "answer = react_agent.invoke({\"messages\": [\"What issues could arrise due to missing HITL control with your current tooling? Keep it concise. Mention your tools.\"]})\n",
    "display(Markdown(answer[\"messages\"][-1].content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### New agent architecture: From ReAct Agent to HITL control\n",
    "The prebuilt `create_react_agent` lacks Human-in-the-Loop (HITL) control for sensitive operations like `post_records`. To address this, we'll build a custom agent from scratch using LangGraph's core components, which will also introduce you to the framework's fundamentals.\n",
    "\n",
    "Our custom agent will have a three-node architecture:\n",
    "\n",
    "- **Agent Node**: Decides the next action by calling the LLM.\n",
    "- **Review Node**: Acts as our HITL control, intercepting actions like `post_records` to ask for user confirmation.\n",
    "- **Tool Node**: Executes the approved tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <iframe\n",
       "    sandbox=\"allow-scripts\"\n",
       "    src=\"data:text/html;base64,PCFkb2N0eXBlIGh0bWw+CiAgICA8aHRtbD48aGVhZD48bWV0YSBjaGFyc2V0PSJ1dGYtOCI+PC9oZWFkPgogICAgPGJvZHk+CiAgICA8ZGl2IGNsYXNzPSJtZXJtYWlkIj4tLS0KY29uZmlnOgogIGZsb3djaGFydDoKICAgIGN1cnZlOiBsaW5lYXIKLS0tCmdyYXBoIFREOwoJX19zdGFydF9fKFs8cD5fX3N0YXJ0X188L3A+XSk6OjpmaXJzdAoJYWdlbnQoYWdlbnQpCgl0b29scyh0b29scykKCV9fZW5kX18oWzxwPl9fZW5kX188L3A+XSk6OjpsYXN0CglfX3N0YXJ0X18gLS0+IGFnZW50OwoJdG9vbHMgLS0+IGFnZW50OwoJYWdlbnQgLS4tPiB0b29sczsKCWFnZW50IC0uLT4gX19lbmRfXzsKCWNsYXNzRGVmIGRlZmF1bHQgZmlsbDojZjJmMGZmLGxpbmUtaGVpZ2h0OjEuMgoJY2xhc3NEZWYgZmlyc3QgZmlsbC1vcGFjaXR5OjAKCWNsYXNzRGVmIGxhc3QgZmlsbDojYmZiNmZjCjwvZGl2PgogICAgPHNjcmlwdCBzcmM9Imh0dHBzOi8vY2RuLmpzZGVsaXZyLm5ldC9ucG0vbWVybWFpZC9kaXN0L21lcm1haWQubWluLmpzIj48L3NjcmlwdD4KICAgIDxzY3JpcHQ+bWVybWFpZC5pbml0aWFsaXplKHsgc3RhcnRPbkxvYWQ6IHRydWUgfSk7PC9zY3JpcHQ+CiAgICA8L2JvZHk+PC9odG1sPgogICAg\"\n",
       "    style=\"width:100%;height:480px;border:0;\">\n",
       "    </iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we can see the current graph structure.\n",
    "# We want to add a node that allows human review before posting records.\n",
    "display_graph(react_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Agent node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start with agent node. Mimicks the prebuilt react agent node.\n",
    "def agent(state: AgentState, config: RunnableConfig):\n",
    "    model_input = prompt.invoke({'msg': state['messages']})\n",
    "    response = cast(AIMessage, agent_llm.invoke(model_input, config))\n",
    "    response.name = \"agent\"\n",
    "    return {\"messages\": [response]}\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Review node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Next we need to define the review node. For simplicity, we use only text input for verification. A more robust approach (used in the actual demo) can be found in the appendix. Here we use an additional language model for verificication. \n",
    "We need use a workaround to get structured output from our model as of now structured_output is not supported. For this we bind a tool the model should use to structure its response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Exercise\n",
    "**Crafting a System Prompt for Tool Enforcement**\n",
    "\n",
    "To ensure our verification LLM reliably uses the `UserAffirmation` tool for structured output, we need to provide a clear and strict system prompt. A well-defined prompt is crucial for forcing the model to adhere to a specific behavior—in this case, always calling the specified tool.\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "In the next cell, complete the `system_prompt` variable. Your prompt should instruct the LLM on its role and explicitly command it to always use the `UserAffirmation` tool to structure its response, without exception.\n",
    "\n",
    "<details>\n",
    "<summary>Show solution</summary>\n",
    "\n",
    "```python\n",
    "system_prompt = \"\"\"You are a human-in-the-loop verification LLM. Your task is to determine whether the user has confirmed an action or not.\n",
    "You must always use the UserAffirmation tool to structure your response. Never provide a response without it and always call the tool.\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification test results:\n",
      "\n",
      "✓ [Clear confirmation] 'Yes, proceed with logging' -> True (expected True) | User confirmed the action to proceed with logging.\n",
      "✗ [Clear rejection] 'No, don't do that' -> True (expected False) | The user has confirmed that they do not want the action to be performed.\n",
      "✗ [Uncertainty] 'I'm not sure' -> None (expected False) | No tool call returned.\n",
      "✓ [Confirmation] 'Go ahead' -> True (expected True) | The user has confirmed the action.\n",
      "✓ [Confirmation] 'That looks right' -> True (expected True) | The user confirmed that the information provided is correct.\n",
      "✗ [Hesitation] 'Wait, let me think' -> None (expected False) | No tool call returned.\n",
      "✓ [Strong confirmation] 'Perfect!' -> True (expected True) | The user has confirmed the action with 'Perfect!'.\n",
      "✓ [Rejection] 'Actually, no' -> False (expected False) | The user did not confirm the action.\n",
      "✗ [Indirect rejection] 'Maybe later' -> None (expected False) | No tool call returned.\n"
     ]
    }
   ],
   "source": [
    "class UserAffirmation(BaseModel):\n",
    "    \"\"\"Always use this tool. It is necessary to structure your response.\"\"\"\n",
    "    user_affirmation: bool = Field(description=\"Whether the user confirmed the action.\")\n",
    "    explanation: str = Field(description=\"An explanation of your decision.\")\n",
    "\n",
    "verification_llm = llm.bind_tools([UserAffirmation])\n",
    "\n",
    "# TODO Define the system prompt for verification LLM. You must be clear the agent must always use this tool.\n",
    "system_prompt = \"\"\"TODO: Write this prompt.\"\"\"\n",
    "\n",
    "unit_test(verification_llm, system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification test results:\n",
      "\n",
      "✓ [Clear confirmation] 'Yes, proceed with logging' -> True (expected True) | The user has confirmed the action by stating 'Yes, proceed with logging.'\n",
      "✓ [Clear rejection] 'No, don't do that' -> False (expected False) | The user has clearly stated 'No, don't do that', indicating they do not want the action to be performed.\n",
      "✓ [Uncertainty] 'I'm not sure' -> False (expected False) | The user expressed uncertainty and did not confirm the action.\n",
      "✓ [Confirmation] 'Go ahead' -> True (expected True) | The user has confirmed the action by stating 'Go ahead'.\n",
      "✓ [Confirmation] 'That looks right' -> True (expected True) | The user stated 'That looks right,' which indicates confirmation of the action.\n",
      "✓ [Hesitation] 'Wait, let me think' -> False (expected False) | The user has requested more time to think and has not confirmed the action.\n",
      "✓ [Strong confirmation] 'Perfect!' -> True (expected True) | The user used the word 'Perfect!' which indicates a positive confirmation of the action.\n",
      "✓ [Rejection] 'Actually, no' -> False (expected False) | The user has explicitly stated 'Actually, no', indicating that they have not confirmed the action.\n",
      "✓ [Indirect rejection] 'Maybe later' -> False (expected False) | The user has not confirmed the action and has indicated a preference to delay or reconsider it later.\n"
     ]
    }
   ],
   "source": [
    "class UserAffirmation(BaseModel):\n",
    "    \"\"\"Always use this tool. It is necessary to structure your response.\"\"\"\n",
    "    user_affirmation: bool = Field(description=\"Whether the user confirmed the action.\")\n",
    "    explanation: str = Field(description=\"An explanation of your decision.\")\n",
    "\n",
    "verification_llm = llm.bind_tools([UserAffirmation])\n",
    "\n",
    "# TODO Define the system prompt for verification LLM. You must be very clear to always use the tool.\n",
    "system_prompt = \"\"\"You are a human-in-the-loop verification LLM. Your task is to determine whether the user has confirmed an action or not.\n",
    "You must always use the UserAffirmation tool to structure your response. Never provide a response without it and always call the tool.\"\"\"\n",
    "\n",
    "unit_test(verification_llm, system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Review node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The `human_review` node intercepts `post_records` tool calls to request user confirmation via an `interrupt`. If no such calls are present, control passes directly to the `tools` node.\n",
    "\n",
    "After the user responds to the interrupt, a verification LLM processes their input.\n",
    "- **If approved**, execution proceeds to the `tools` node.\n",
    "- **If denied**, a `ToolMessage` is added to the state, and control returns to the `agent` node.\n",
    "\n",
    "**Key Points:**\n",
    "- A `ToolMessage` is required for every tool call.\n",
    "- After an `interrupt`, the `human_review` node re-executes from the beginning, which is a common pitfall to be aware of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "def human_review(state: AgentState) -> Command[Literal[\"agent\", \"tools\"]]:\n",
    "    # Check if the last message contains a call to post_records\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    post_record_calls = [tool_call for tool_call in last_message.tool_calls if tool_call['name'] == 'post_records']\n",
    "\n",
    "    # If there is a post_records call, ask for user confirmation\n",
    "    if len(post_record_calls) > 0:\n",
    "\n",
    "        # Get the confirmation message from the tool call arguments and ask the user to review\n",
    "        confirmation_message = [call[\"args\"][\"confirmation_message\"] for call in post_record_calls]\n",
    "        user_review = interrupt({\"task\": \"Review the action.\",\n",
    "                           \"action\": confirmation_message})\n",
    "        \n",
    "        # Use the verification LLM to determine if the user confirmed the action\n",
    "        output = verification_llm.invoke(\n",
    "            [('user', user_review), ('system', 'Verify whether the user wants to continue with the action.')])\n",
    "        # Extract the user affirmation result\n",
    "        should_continue = output.tool_calls[0]['args']['user_affirmation']\n",
    "        print(f\"Model explanation: {output.tool_calls[0]['args']['explanation']}\")\n",
    "\n",
    "        # If user confirmed, proceed to tools node, else go back to agent node\n",
    "        if should_continue:\n",
    "            # With Send we can select the next node and pass the current state\n",
    "            return Send(node='tools', arg=state)\n",
    "        else:\n",
    "            # With Command we can select the next node and update the state\n",
    "            return Command(update={\"messages\": [ToolMessage('User did not confirm action.', tool_call_id=call['id']) for call in post_record_calls]}, goto='agent')\n",
    "    else:\n",
    "        return Send(node='tools', arg=state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Exercise\n",
    "**Determine the Next Node**\n",
    "\n",
    "Understand the logic of the `human_review` node, decide which node the graph will transition to in each of the following scenarios. Fill in the blanks before revealing the answers.\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "1.  **Scenario A:**\n",
    "    -   Last AI tool calls: `[get_records]`\n",
    "    -   Next node: _______\n",
    "\n",
    "2.  **Scenario B:**\n",
    "    -   Last AI tool calls: `[post_records(...)]`\n",
    "    -   User affirms (`should_continue = True`)\n",
    "    -   Next node: _______\n",
    "\n",
    "3.  **Scenario C:**\n",
    "    -   Last AI tool calls: `[post_records(...)]`\n",
    "    -   User declines (`should_continue = False`)\n",
    "    -   Next node: _______\n",
    "\n",
    "<details>\n",
    "<summary>Show Answers</summary>\n",
    "\n",
    "1.  **Scenario A** -> `tools`\n",
    "2.  **Scenario B** -> `tools`\n",
    "3.  **Scenario C** -> `agent`\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Tool Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "For the tools node we use the prebuilt ToolNode. It retrieves the tool calls from the last AIMessage and executes them. It provides a tool message for every tool call and appends it to the message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_tools = [post_records, get_today, get_records]\n",
    "agent_llm = llm.bind_tools(agent_tools)\n",
    "tool_node = ToolNode(agent_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Build the new agent and define control flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now we build our graph by adding the nodes and edges. Edges define what nodes to execute next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <iframe\n",
       "    sandbox=\"allow-scripts\"\n",
       "    src=\"data:text/html;base64,PCFkb2N0eXBlIGh0bWw+CiAgICA8aHRtbD48aGVhZD48bWV0YSBjaGFyc2V0PSJ1dGYtOCI+PC9oZWFkPgogICAgPGJvZHk+CiAgICA8ZGl2IGNsYXNzPSJtZXJtYWlkIj4tLS0KY29uZmlnOgogIGZsb3djaGFydDoKICAgIGN1cnZlOiBsaW5lYXIKLS0tCmdyYXBoIFREOwoJX19zdGFydF9fKDxwPl9fc3RhcnRfXzwvcD4pCglhZ2VudChbYWdlbnRdKTo6Omxhc3QKCXRvb2xzKHRvb2xzKQoJaHVtYW5fcmV2aWV3KGh1bWFuX3JldmlldykKCV9fc3RhcnRfXyAtLT4gYWdlbnQ7Cgl0b29scyAtLT4gYWdlbnQ7CglodW1hbl9yZXZpZXcgLS4tPiBhZ2VudDsKCWh1bWFuX3JldmlldyAtLi0+IHRvb2xzOwoJY2xhc3NEZWYgZGVmYXVsdCBmaWxsOiNmMmYwZmYsbGluZS1oZWlnaHQ6MS4yCgljbGFzc0RlZiBmaXJzdCBmaWxsLW9wYWNpdHk6MAoJY2xhc3NEZWYgbGFzdCBmaWxsOiNiZmI2ZmMKPC9kaXY+CiAgICA8c2NyaXB0IHNyYz0iaHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L25wbS9tZXJtYWlkL2Rpc3QvbWVybWFpZC5taW4uanMiPjwvc2NyaXB0PgogICAgPHNjcmlwdD5tZXJtYWlkLmluaXRpYWxpemUoeyBzdGFydE9uTG9hZDogdHJ1ZSB9KTs8L3NjcmlwdD4KICAgIDwvYm9keT48L2h0bWw+CiAgICA=\"\n",
       "    style=\"width:100%;height:480px;border:0;\">\n",
       "    </iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def init_agent(tool_node):\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    workflow.add_node('agent', agent)\n",
    "    workflow.add_node('tools', tool_node)\n",
    "    workflow.add_node('human_review', human_review)\n",
    "\n",
    "    workflow.add_edge(START, \"agent\")\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "    return workflow\n",
    "\n",
    "workflow = init_agent(tool_node)\n",
    "\n",
    "#Mermaid API is experiencing issues currently. Hotfix\n",
    "# display(workflow.compile())\n",
    "\n",
    "# Here you can see the current graph structure with the new human_review node.\n",
    "# As you can see the agent node is not connected to anything yet.\n",
    "display_graph(workflow.compile())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Define control flow with Conditional edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Conditional edges define what node to execute next based on a condition. We add a conditional edge which routes the execution from the agent node either to the review node or the end node depending on whether the language model executed a tool call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <iframe\n",
       "    sandbox=\"allow-scripts\"\n",
       "    src=\"data:text/html;base64,PCFkb2N0eXBlIGh0bWw+CiAgICA8aHRtbD48aGVhZD48bWV0YSBjaGFyc2V0PSJ1dGYtOCI+PC9oZWFkPgogICAgPGJvZHk+CiAgICA8ZGl2IGNsYXNzPSJtZXJtYWlkIj4tLS0KY29uZmlnOgogIGZsb3djaGFydDoKICAgIGN1cnZlOiBsaW5lYXIKLS0tCmdyYXBoIFREOwoJX19zdGFydF9fKFs8cD5fX3N0YXJ0X188L3A+XSk6OjpmaXJzdAoJYWdlbnQoYWdlbnQpCgl0b29scyh0b29scykKCWh1bWFuX3JldmlldyhodW1hbl9yZXZpZXcpCglfX2VuZF9fKFs8cD5fX2VuZF9fPC9wPl0pOjo6bGFzdAoJX19zdGFydF9fIC0tPiBhZ2VudDsKCXRvb2xzIC0tPiBhZ2VudDsKCWFnZW50IC0uICZuYnNwO3Rvb2wgY2FsbCZuYnNwOyAuLT4gaHVtYW5fcmV2aWV3OwoJYWdlbnQgLS4tPiBfX2VuZF9fOwoJaHVtYW5fcmV2aWV3IC0uLT4gYWdlbnQ7CglodW1hbl9yZXZpZXcgLS4tPiB0b29sczsKCWNsYXNzRGVmIGRlZmF1bHQgZmlsbDojZjJmMGZmLGxpbmUtaGVpZ2h0OjEuMgoJY2xhc3NEZWYgZmlyc3QgZmlsbC1vcGFjaXR5OjAKCWNsYXNzRGVmIGxhc3QgZmlsbDojYmZiNmZjCjwvZGl2PgogICAgPHNjcmlwdCBzcmM9Imh0dHBzOi8vY2RuLmpzZGVsaXZyLm5ldC9ucG0vbWVybWFpZC9kaXN0L21lcm1haWQubWluLmpzIj48L3NjcmlwdD4KICAgIDxzY3JpcHQ+bWVybWFpZC5pbml0aWFsaXplKHsgc3RhcnRPbkxvYWQ6IHRydWUgfSk7PC9zY3JpcHQ+CiAgICA8L2JvZHk+PC9odG1sPgogICAg\"\n",
       "    style=\"width:100%;height:480px;border:0;\">\n",
       "    </iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def should_continue(state: AgentState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, \"tool_calls\") and len(last_message.tool_calls) > 0:\n",
    "        return \"tool call\"\n",
    "    return \"__end__\"\n",
    "\n",
    "workflow.add_conditional_edges(source=\"agent\", path=should_continue, path_map={\"tool call\": \"human_review\", \"__end__\": END})\n",
    "\n",
    "\n",
    "# display(workflow.compile())\n",
    "display_graph(workflow.compile())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Finalize by compiling the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Finally, we compile our graph. When compiling we add a checkpointer to achieve thread level persistence. With a checkpointer specified at compilation, a snapshot of the graph state is saved at every superstep. This is crucial for human-in-the-loop interactions as we need to resume execution after an interrupt is called. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <iframe\n",
       "    sandbox=\"allow-scripts\"\n",
       "    src=\"data:text/html;base64,PCFkb2N0eXBlIGh0bWw+CiAgICA8aHRtbD48aGVhZD48bWV0YSBjaGFyc2V0PSJ1dGYtOCI+PC9oZWFkPgogICAgPGJvZHk+CiAgICA8ZGl2IGNsYXNzPSJtZXJtYWlkIj4tLS0KY29uZmlnOgogIGZsb3djaGFydDoKICAgIGN1cnZlOiBsaW5lYXIKLS0tCmdyYXBoIFREOwoJX19zdGFydF9fKFs8cD5fX3N0YXJ0X188L3A+XSk6OjpmaXJzdAoJYWdlbnQoYWdlbnQpCgl0b29scyh0b29scykKCWh1bWFuX3JldmlldyhodW1hbl9yZXZpZXcpCglfX2VuZF9fKFs8cD5fX2VuZF9fPC9wPl0pOjo6bGFzdAoJX19zdGFydF9fIC0tPiBhZ2VudDsKCXRvb2xzIC0tPiBhZ2VudDsKCWFnZW50IC0uICZuYnNwO3Rvb2wgY2FsbCZuYnNwOyAuLT4gaHVtYW5fcmV2aWV3OwoJYWdlbnQgLS4tPiBfX2VuZF9fOwoJaHVtYW5fcmV2aWV3IC0uLT4gYWdlbnQ7CglodW1hbl9yZXZpZXcgLS4tPiB0b29sczsKCWNsYXNzRGVmIGRlZmF1bHQgZmlsbDojZjJmMGZmLGxpbmUtaGVpZ2h0OjEuMgoJY2xhc3NEZWYgZmlyc3QgZmlsbC1vcGFjaXR5OjAKCWNsYXNzRGVmIGxhc3QgZmlsbDojYmZiNmZjCjwvZGl2PgogICAgPHNjcmlwdCBzcmM9Imh0dHBzOi8vY2RuLmpzZGVsaXZyLm5ldC9ucG0vbWVybWFpZC9kaXN0L21lcm1haWQubWluLmpzIj48L3NjcmlwdD4KICAgIDxzY3JpcHQ+bWVybWFpZC5pbml0aWFsaXplKHsgc3RhcnRPbkxvYWQ6IHRydWUgfSk7PC9zY3JpcHQ+CiAgICA8L2JvZHk+PC9odG1sPgogICAg\"\n",
       "    style=\"width:100%;height:480px;border:0;\">\n",
       "    </iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "checkpointer = MemorySaver()\n",
    "timesheet_agent = workflow.compile(checkpointer=checkpointer)\n",
    "display_graph(timesheet_agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Add a system prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In order to ensure consistent and useful behaviour we need to define a well structured system prompt next. \n",
    "Generally, you should:\n",
    "  1. Define the role and persona.\n",
    "  2. Establish context and objectives\n",
    "  3. Outline clear instructions and constraints\n",
    "  4. Provide examples of ideal responses (Optional)\n",
    "\n",
    "\n",
    "By utilizing few-shot prompting model performance can be hugely improved. It also makes sense to encourage iterative clarification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt =f\"\"\"\n",
    "Role and Objective:\n",
    "  - You are a helpful AI Agent dedicated to assisting users with time recording.\n",
    "  - Your primary tasks include retrieving and posting timesheet data based on user requests.\n",
    "\n",
    "Responsibilities:\n",
    "  - Logging Work Time: Only log actual work time. Do not include any breaks.\n",
    "    - User: Today I worked from 6 to 16 with a half hour break at 12. -> You should: Log time from 6 to 12 and from 12:30 to 16.\n",
    "  - Data Handling: When posting records, execute as many post_records calls in parallel as possible using the provided information.\n",
    "  - When calling a tool always describe the step you are taking in the message containing the tool call.\n",
    "\n",
    "Interaction Guidelines:\n",
    "  - The user's most recent input always takes precedence over older input.\n",
    "  - Do not ask the user for confirmation.\n",
    "  - Always provide a confirmation_message in the tool call when posting records.\n",
    "  - Language Consistency: Always respond in the same language as the user.\n",
    "  - If the user’s request is too ambiguous (for example, very unclear work times), ask clarifying questions rather than making farfetched assumptions.\n",
    "  - Use your tools to retrieve the exact dates.\n",
    "  - If the user mentions a specific week and weekday use your tools to infer the date. Never ask the user for the date in this case.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_prompt),\n",
    "    MessagesPlaceholder(variable_name='msg')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Test out the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now we can stream the output of our agent. We hand over a dictionary containing the user's input and a config with our thread id. Each thread represents an individual session betweeen the graph and the user. So, if we want to continue our conversation, we need to pass the same thread id to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: agent\n",
      "Tool Calls:\n",
      "  get_today (call_adzIlDF6kSqNae0Sw0zisPWb)\n",
      " Call ID: call_adzIlDF6kSqNae0Sw0zisPWb\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_today\n",
      "\n",
      "2025-09-26\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: agent\n",
      "Tool Calls:\n",
      "  post_records (call_bu6bw60UktFxiSAES1SyhtYX)\n",
      " Call ID: call_bu6bw60UktFxiSAES1SyhtYX\n",
      "  Args:\n",
      "    data: {'startDate': '2025-09-26', 'startTime': 'PT06H00M00S', 'endTime': 'PT12H00M00S'}\n",
      "    confirmation_message: Confirm work time from 06:00 to 12:00 on Friday, September 26th 2025.\n",
      "  post_records (call_a8XwSxbLXnk4KlKP6c2uv5kZ)\n",
      " Call ID: call_a8XwSxbLXnk4KlKP6c2uv5kZ\n",
      "  Args:\n",
      "    data: {'startDate': '2025-09-26', 'startTime': 'PT12H30M00S', 'endTime': 'PT18H00M00S'}\n",
      "    confirmation_message: Confirm work time from 12:30 to 18:00 on Friday, September 26th 2025.\n",
      "Interrupt(value={'task': 'Review the action.', 'action': ['Confirm work time from 06:00 to 12:00 on Friday, September 26th 2025.', 'Confirm work time from 12:30 to 18:00 on Friday, September 26th 2025.']}, resumable=True, ns=['human_review:177ddc2e-0165-a063-46f3-e831bccbb984'], when='during')\n",
      "Model explanation: The user has confirmed the action by stating 'Sure.'\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: post_records\n",
      "\n",
      "Entity created successfully: startDate='2025-09-26' startTime='PT12H30M00S' endTime='PT18H00M00S'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: agent\n",
      "\n",
      "Your work times for today have been successfully logged:\n",
      "- From 06:00 to 12:00\n",
      "- From 12:30 to 18:00\n",
      "\n",
      "Is there anything else I can assist you with?\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid1())}}\n",
    "\n",
    "user_input = {'messages': ['user', 'Today, I worked from 6 to 6 with a half hour break at 12.']}\n",
    "process_output(timesheet_agent.stream(user_input, config, stream_mode='updates'))\n",
    "\n",
    "user_input = Command(resume='Sure.')\n",
    "process_output(timesheet_agent.stream(user_input, config, stream_mode='updates'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Interact with the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now you can try interacting with the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type to interact with the agent (type q to quit):\n",
      "\n",
      "hi\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: agent\n",
      "\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "\n",
      "today from 8 to 4\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: agent\n",
      "Tool Calls:\n",
      "  get_today (call_nuxFyFNEeoXdUN5qIb9sAr63)\n",
      " Call ID: call_nuxFyFNEeoXdUN5qIb9sAr63\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_today\n",
      "\n",
      "2025-09-26\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: agent\n",
      "Tool Calls:\n",
      "  post_records (call_DAyJHNDaSMUWEBY72IRjPyhI)\n",
      " Call ID: call_DAyJHNDaSMUWEBY72IRjPyhI\n",
      "  Args:\n",
      "    data: {'startDate': '2025-09-26', 'startTime': 'PT08H00M00S', 'endTime': 'PT16H00M00S'}\n",
      "    confirmation_message: Confirm work time from 08:00 to 16:00 on Friday, September 26th 2025.\n",
      "Interrupt(value={'task': 'Review the action.', 'action': ['Confirm work time from 08:00 to 16:00 on Friday, September 26th 2025.']}, resumable=True, ns=['human_review:aa988fd9-9f51-41b5-2a91-ba6230b38c35'], when='during')\n",
      "ja klar\n",
      "Model explanation: The user has confirmed the action by saying 'ja klar' which means 'yes, sure' in German.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: post_records\n",
      "\n",
      "Entity created successfully: startDate='2025-09-26' startTime='PT08H00M00S' endTime='PT16H00M00S'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: agent\n",
      "\n",
      "Your work time from 08:00 to 16:00 on Friday, September 26th, 2025 has been successfully logged. If you need any further assistance, feel free to ask!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid1())}}\n",
    "interrupted = False\n",
    "\n",
    "print(\"Type to interact with the agent (type q to quit):\\n\")\n",
    "while True:\n",
    "    user_input = input()\n",
    "    if user_input.lower() == 'q':\n",
    "        break\n",
    "    print(user_input)\n",
    "\n",
    "    if interrupted:\n",
    "        interrupted = False\n",
    "        user_input = Command(resume=user_input)\n",
    "    else:\n",
    "        user_input = {'messages': ['user', user_input]}\n",
    "\n",
    "    interrupted = process_output(timesheet_agent.stream(user_input, config, stream_mode=\"updates\"))\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Extension with MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Get MCP tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Retrieve required tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extension with MCP / Community Tool Kits\n",
    "\n",
    "# Retrieve MCP token from environment variable or use default for demo purposes\n",
    "MCP_TOKEN = os.environ.get(\"MCP_TOKEN\", None)\n",
    "if MCP_TOKEN is None:\n",
    "    raise ValueError(\"MCP_TOKEN environment variable is not set.\")\n",
    "url = os.environ.get(\"MCP_API_BASE_URL\", None)\n",
    "if url is None:\n",
    "    raise ValueError(\"MCP_API_BASE_URL environment variable is not set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define MCP server configurations\n",
    "def http_mcp_server(url):\n",
    "    # url = url.rstrip(\"/\")\n",
    "    return {\n",
    "        \"email\": {\n",
    "            \"transport\": \"streamable_http\",\n",
    "            \"url\": url,\n",
    "            \"headers\": {\"Authorization\": f\"Bearer {MCP_TOKEN}\"}\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize MCP client and load email tools\n",
    "mcp = MultiServerMCPClient(http_mcp_server(url))\n",
    "email_tools = await mcp.get_tools(server_name=\"email\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Update agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tools from MCP server. Available tools: ['search_messages', 'get_message']\n"
     ]
    }
   ],
   "source": [
    "# Combine with existing tools\n",
    "tools = [get_today, get_records, post_records, *email_tools]\n",
    "print(f\"Loaded tools from MCP server. Available tools: {[tool.name for tool in email_tools]}\")\n",
    "agent_llm = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reinitialize workflow with new tools\n",
    "tools_node = ToolNode(tools)\n",
    "workflow = init_agent(tool_node=tools_node)\n",
    "workflow.add_conditional_edges(\n",
    "    source=\"agent\",\n",
    "    path=should_continue,\n",
    "    path_map={\"tool call\": \"human_review\", \"__end__\": END}\n",
    ")\n",
    "\n",
    "# Finalize agent with checkpointer to retain state across sessions\n",
    "new_agent  = workflow.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Test out the new MCP capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Please check my email inbox.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: agent\n",
      "Tool Calls:\n",
      "  search_messages (call_Mi9dXVmRYrwT1kUPmUmjUw7m)\n",
      " Call ID: call_Mi9dXVmRYrwT1kUPmUmjUw7m\n",
      "  Args:\n",
      "    limit: 10\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_messages\n",
      "\n",
      "[{\"id\":\"1994d12b9574738a\",\"thread_id\":\"1994d12b9574738a\",\"subject\":\"Workshop Notes\",\"from\":\"\\\"Abdulla, Can\\\" <can.abdulla@sap.com>\",\"date\":\"Mon, 15 Sep 2025 11:11:30 +0000\",\"preview_text\":\"Hi Alice,\\r\\n\\r\\nThanks for the workshop today from 14:00–16:00 with our team.\\r\\nPlease send the notes wh...\"}]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "You have one email in your inbox:\n",
       "\n",
       "- **Subject:** Workshop Notes\n",
       "- **From:** \"Abdulla, Can\" <can.abdulla@sap.com>\n",
       "- **Date:** Mon, 15 Sep 2025 11:11:30 +0000\n",
       "- **Preview:** Hi Alice, Thanks for the workshop today from 14:00–16:00 with our team. Please send the notes wh...\n",
       "\n",
       "Would you like to read the full email?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the agent with email tools\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid1())}}\n",
    "answer = await new_agent.ainvoke({\"messages\": [\"Please check my email inbox.\"]}, config)\n",
    "for msg in answer[\"messages\"][:-1]:\n",
    "    msg.pretty_print()\n",
    "\n",
    "display(Markdown(answer[\"messages\"][-1].content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
